{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "239962eb-a3df-418b-961e-ae2262944606",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col, lit, current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95ce4482-d858-4292-a908-8931903f6b12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def func_scd2(target_delta ,source,key_cols):\n",
    "  \n",
    "    scd_cols = [\"start_date\",\"end_date\",\"is_current\",\"hash\",\"key\"]\n",
    "\n",
    "    target = target_delta.toDF()\n",
    "\n",
    "    # Identify the columns which are not key or scd columns \n",
    "    hash_columns = list(set(target.columns) - set(key_cols) - set(scd_cols))\n",
    "    print(hash_columns)\n",
    "\n",
    "    # Those columns will help us to identify the insert's and updates\n",
    "    source = source.withColumn('key',F.concat_ws('',*key_cols))\\\n",
    "                   .withColumn(\"hash\",F.sha2(F.concat_ws(\"||\",*hash_columns),256))         \n",
    "\n",
    "    # Process to identify the inserts (via key) and updates (via hash)\n",
    "    inserts = source.alias('src').join(target.alias('trg').where('trg.is_current = True'), on='key', how='left')\\\n",
    "                                 .where('trg.key is null')\n",
    "\n",
    "    updates = source.alias('src').join(target.alias('trg').where('trg.is_current = True'), on = 'key', how='inner')\\\n",
    "                                .where('src.hash <> trg.hash')\n",
    "\n",
    "\n",
    "    # Based on this column \"mergekey\" we will perfrom the MERGE operation\n",
    "    inserts = inserts.selectExpr(\"NULL as mergekey\",\"src.*\")\n",
    "    updates = updates.selectExpr(\"key as mergekey\",\"src.*\")\n",
    "\n",
    "\n",
    "    # Union the inserts and updates\n",
    "    # All of those records should be ingested into target table\n",
    "    final_df_before_ingestion = inserts.unionByName(updates)\n",
    "\n",
    "\n",
    "    # MERGE: target - final_df_before_ingestion\n",
    "    # SOS: Our goal is to identify only the changed records which are not current and update the end_date\n",
    "    target_delta.alias('trg').merge(\n",
    "        final_df_before_ingestion.alias('src'),\n",
    "        \"trg.key = src.mergekey\"\n",
    "    )\\\n",
    "    .whenMatchedUpdate(\n",
    "        condition = \"trg.is_current = True AND trg.hash <> src.hash\",\n",
    "        set = {\n",
    "          \"is_current\": lit(False),\n",
    "          \"end_date\": lit(datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "        }\n",
    "    ).execute()\n",
    "\n",
    "    # Prepare the records to be ingested\n",
    "    final_df_before_ingestion = final_df_before_ingestion \\\n",
    "        .withColumn(\"is_current\", lit('True')) \\\n",
    "        .withColumn(\"start_date\", lit(datetime.now().strftime(\"%Y-%m-%d\"))) \\\n",
    "        .withColumn(\"end_date\", lit(None))\\\n",
    "        .drop(\"mergekey\")\n",
    "\n",
    "    # Append new records to Delta table\n",
    "    final_df_before_ingestion.write.format(\"delta\").mode(\"append\").saveAsTable(\"cappa_ds_dev.default.my_test_table_scd\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "functions_scd2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}